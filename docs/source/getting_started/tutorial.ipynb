{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skillmodels Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from estimagic import maximize\n",
    "from skillmodels.config import TEST_DIR\n",
    "from skillmodels.likelihood_function import get_maximization_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model Specification and Data\n",
    "\n",
    "Model specifications are python dictionaries that can be safed in yaml or json files. For a moment, just assume you know how to write a model specification and have a skillmodels compatible dataset. Both are \n",
    "explained in different tutorials.\n",
    "\n",
    "Next we load the model specification and the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_DIR / \"model2.yaml\") as y:\n",
    "    model_dict = yaml.load(y, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata(TEST_DIR / \"model2_simulated_data.dta\")\n",
    "data.set_index([\"caseid\", \"period\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the inputs for ``estimagic.maximize``\n",
    "\n",
    "Skillmodels basically just has one public function called ``get_maximization_inputs``. When called with a model specification and a dataset it contains a dictionary with everything you need to maximize the likelihood function using estimagic. \n",
    "\n",
    "By everything you need I mean everything model specific. You should still use the optional arguments of ``maximize`` to tune the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_inputs = get_maximization_inputs(model_dict, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the Params Template\n",
    "\n",
    "Often you can greatly reduce estimation time by choosing good start parameters. What are good start parameters depends strongly on the model specifications, the scaling of your variables and the normalizations you make. \n",
    "\n",
    "If you have strong difficulties to pick good start values, you probably want to think again about the interpretability of your model parameters and possibly change the normalizations and scaling of your \n",
    "measurements. \n",
    "\n",
    "As a rule of thumb: If all measurements are standardized and, all fixed loadings are 1 and all fixed intercepts are 0 then one is a good start value for all free loadings and 0 is a good start value for all free intercepts. \n",
    "\n",
    "Measurement and shock standard deviations are better started slightly larger than you would expect them. \n",
    "\n",
    "Below I just load start parameters for the CHS example model that I filled out manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_template = max_inputs[\"params_template\"]\n",
    "params_template.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\"category\", \"period\", \"name1\", \"name2\"]\n",
    "chs_path = TEST_DIR / \"regression_vault\" / \"chs_results.csv\"\n",
    "chs_values = pd.read_csv(chs_path)\n",
    "chs_values.set_index(index_cols, inplace=True)\n",
    "chs_values = chs_values[[\"chs_value\", \"good_start_value\", \"bad_start_value\"]]\n",
    "chs_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params_template.copy()\n",
    "params[\"value\"] = chs_values[\"chs_value\"]\n",
    "params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time compilation speed\n",
    "\n",
    "Skillmodels uses jax to just-in-time compile the numerical code and get a gradient of the likelihood function by automatic differentiation. \n",
    "\n",
    "There are several versions of the log likelihood function and its gradient:\n",
    "\n",
    "- **debug_loglike**: Is not compiled, can be debugged with a debugger, returns a lot of intermediate outputs and is slow. \n",
    "- **loglike**: Is compiled and fast but does not return intermediate outputs\n",
    "- **gradient**: Is compiled and fast, returns the gradient of loglike\n",
    "- **loglike_and_gradient**: Is compiled and fast and exploits synergies between loglike and gradient calculation. This is the most important one for estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_loglike = max_inputs[\"debug_loglike\"]\n",
    "loglike = max_inputs[\"loglike\"]\n",
    "gradient = max_inputs[\"gradient\"]\n",
    "jacobian = max_inputs[\"jacobian\"]\n",
    "loglike_and_gradient = max_inputs[\"loglike_and_gradient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "debug_loglike_value = debug_loglike(params)\n",
    "print(time() - start)\n",
    "debug_loglike_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "loglike_value = loglike(params)\n",
    "print(time() - start)\n",
    "loglike_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loglike(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "gradient_value = gradient(params)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit gradient(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "jacobian_value = jacobian(params)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit jacobian(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_rev = get_maximization_inputs(model_dict, data, jacobian_type=\"jacrev\")[\n",
    "    \"jacobian\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "jacobian_value = jacobian_rev(params)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit jacobian_rev(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "loglike_and_gradient_value = loglike_and_gradient(params)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loglike_and_gradient(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A few additional constraints\n",
    "\n",
    "To get the same values as CHS we will have to do a little more work. The reason is that on top of the many constraints skillmodels generates atuomatically from the model specification, CHS impose two more constraints:\n",
    "\n",
    "1. All but the self productivity paramet in the linear transition equaltion are fixed to zero\n",
    "2. The initial mean of the states is not estimated but assumed to be zero.\n",
    "3. The anchoring parameters (intercepts, control variables, loadings and SDs of measurement error are pairwise equal across periods).\n",
    "\n",
    "Fortunately, estimagic makes it easy to express such constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = max_inputs[\"constraints\"]\n",
    "\n",
    "additional_constraints = [\n",
    "    {\n",
    "        \"query\": \"category == 'transition' & name1 == 'fac2' & name2 != 'fac2'\",\n",
    "        \"type\": \"fixed\",\n",
    "        \"value\": 0,\n",
    "    },\n",
    "    {\"loc\": \"initial_states\", \"type\": \"fixed\", \"value\": 0},\n",
    "    {\n",
    "        \"queries\": [f\"period == {i} & name1 == 'Q1_fac1'\" for i in range(8)],\n",
    "        \"type\": \"pairwise_equality\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = constraints + additional_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a group column for better dashboard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estimagic.optimization.process_constraints import process_constraints\n",
    "\n",
    "pc, pp = process_constraints(constraints, params)\n",
    "params[\"group\"] = params.index.get_level_values(\"category\")\n",
    "params.loc[\"controls\", \"group\"] = params.loc[\"controls\"].index.get_level_values(\"name2\")\n",
    "\n",
    "params[\"group\"] = (\n",
    "    params[\"group\"].astype(str)\n",
    "    + \"_\"\n",
    "    + params.index.get_level_values(\"period\").astype(str)\n",
    ")\n",
    "params[\"group\"] = params[\"group\"].str.replace(\"_\", \"-\")\n",
    "params[\"group\"] = params[\"group\"].astype(\"O\")\n",
    "params.loc[~pp[\"_internal_free\"], \"group\"] = None\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"value\"] = chs_values[\"good_start_value\"]\n",
    "loc = params.query(\"category == 'shock_sds' & name1 == 'fac3'\").index\n",
    "params.loc[loc, \"lower_bound\"] = 0.00\n",
    "loglike(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = maximize(\n",
    "    criterion=loglike,\n",
    "    params=params,\n",
    "    algorithm=\"scipy_lbfgsb\",\n",
    "    fun_and_jac=loglike_and_gradient,\n",
    "    constraints=constraints,\n",
    "    logging=False,\n",
    "    algo_options={\"convergence.relative_criterion_tolerance\": 1e-9},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"success\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
